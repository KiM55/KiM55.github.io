
<!DOCTYPE html>
<!-- saved from url=(0040)http://artemsheludko.pw/flexible-jekyll/ -->
<html lang="en">


	
<head>
	
<!-- <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?1833684faf5f254c1bb31386c5780c57";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script> -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-87320911-1', 'auto');
  ga('send', 'pageview');

</script>

        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Shiming Chen-陈使明</title>
        <link rel="shortcut icon" href="img/chen1.jpg"/>
        <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
	<meta name="keywords" content="Shimingchen, EIC, HUST, The Huazhong University of Science and Technology"> 
	<meta name="description" content="Shiming Chen's home page">
	<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
	<meta name="google-site-verification" content="yy_3iiS_X6pJdegdwitJMrH0LRLHXwpjrV9RKLXxKjg" />
	<link rel="stylesheet" href="./css/jemdoc.css">
	<title>Shiming Chen, Huazhong University of Science and Technology</title>
</head>

<body>
 <div id="layout-content" style="margin-top:25px">
 <a href="https://github.com/shiming-chen" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250"
 style="fill:#0000FF; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z">
 </path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,
 87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
 <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 
 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,
 77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,
 116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>
 <style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,
 60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px)
 {.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
	
	
	
	
<table>
	<tbody>
		<tr>
			<td width="670">
				<div id="toptitle">					
					<h1>Shiming Chen &nbsp 陈使明 </h1><h1>
				</h1></div>

				<h3> Postdoctoral Research Fellow </h3>
				<p>
<!-- 					1037 Luoyu Road,<br>
					National Anti-counterfeit Engineering Research Center,<br>
					Huazhong University of Science and Technology (HUST), <br>
					Wuhan, China, 430074 <br>
					<br> -->
					Email:  gchenshiming <strong>at</strong> gmail <strong>dot</strong> com
					       
				</p>
				<p>     
					
					<!-- <a href="paper/CV.pdf"><img src="img/cv_p.jpg"  height="40px" style="margin-bottom:-3px"></a> -->
					<a href="https://github.com/shiming-chen"><img src="img/github.jpg" height="40px" style="margin-bottom:-3px"></a>
					<a href="https://scholar.google.com/citations?hl=en&user=botczdcAAAAJ"><img src="img/google-logo.png"  height="40px" style="margin-bottom:-3px"></a>
<!-- 					<a href="img/weichat.pdf"><img src="img/weichat.jpg"  height="40px" style="margin-bottom:-3px"></a> -->
				</p>
			</td>
			<td>
				<a href="https://shiming-chen.github.io/"><img src="img/chen1.jpg" alt="Shiming Chen" border="0" width="300"></a><br>
			</td>
		</tr><tr>
	</tr>
	</tbody>
</table>
	
    <h2>Short Bios</h2>
    <div id="news-content" >
<!-- 	  <span>I come from Meizhou, Guangdong, where is known as “<i>Hakka capital</i>” and “<i> City of Football </i>”.<br> -->
	  <span>
<!-- 		I am currently a Postdoctoral Research Fellow in the <a href="https://www.cmu.edu/dietrich/causality/">Causal Learning and Reasoning (CLeaR)</a> 
		research group at CMU and the <a href="https://mbzuai.ac.ae/research/research-center/ciai/">Center for Integrative AI (CIAI)</a> at MBZUAI, 
		fortunately working with Prof.  <a href="https://www.andrew.cmu.edu/user/kunz1/index.html">Kun Zhang</a>. 
		Prior to that,  -->
		I received my Ph.D. degree at Huazhong University of Science and Technology in Dec. 2022, advised by Prof. <a href="http://bmal.hust.edu.cn/info/1005/1091.html">Xinge You</a> and worked closely Prof. <a href="https://scholar.google.com/citations?user=z84rLjoAAAAJ">Ling Shao</a>.
                My current research interests span computer vision and machine learning with a series of topics, such as <strong><i>zero-shot learning</i></strong>, <strong><i>generative modeling and learning</i></strong>, and <strong><i>visual-and-language learning</i></strong>. </span> <br> <br> 
<!-- 	       <span>I am the <a href="http://valser.org/article-634-1.html">AC</a> of <strong>VALSE</strong>.</span><br> -->
<!-- 	  <span style="color:Red">I'm Looking forward to a position for work or postdoc researcher, please feel free to drop me an email if you have the relevant position.</span> -->
    </div>
	 

      <h2 >News</h2>
    <div style="margin-top: 15px; overflow-y: scroll;">
      <li><span style="color:Red">2023.07</span>, one paper is accepted to <strong><i>ICCV'23</i></strong>.</li>
      <li><span style="color:Red">2023.07</span>, I am invited as an <strong><i>Area Chair (AC)</i></strong> of PRCV'23.</li>
      <li><span style="color:Red">2023.06</span>, I give a talk in University of Science and Technology of China, invited by <strong><a href="http://imcc.ustc.edu.cn/_upload/tpl/0d/13/3347/template3347/xiehongtao.html">Prof. Hongtao Xie</a></strong>.</li>
      <li><span style="color:Red">2023.04</span>, one paper is accepted to <strong><i>ICML'23</i></strong>.</li>
      <li><span style="color:Red">2023.04</span>, I give a talk in Alibaba DAMO Academic, invited by <strong>Baigui Sun</strong>.</li>
      <li><span style="color:Red">2023.04</span>, I give a talk in Huazhong Agricultural Univeristy, invited by <strong><a href="https://chenhongml.github.io/">Prof. Hong Chen</a></strong>.</li>
      <li><span style="color:Red">2023.04</span>, I give a talk in Guizhou University, invited by <strong><a href="https://scholar.google.com/citations?hl=en&user=7879e5QAAAAJ">Prof. Yisong Wang</a></strong>.</li>
      <li><span style="color:Red">2023.03</span>, I am invited as an <strong><i>Area Chair (AC)</i></strong> of VALSE, news at <strong><a href="http://valser.org/article-634-1.html">Here</a></strong>.</li>
      <li><span style="color:Red">2023.03</span>, I give a talk in National Key Laboratory of Science and Technology on Multispectral Information Processing, invited by <strong><a href="https://owuchangyuo.github.io/">Prof. Yi Chang</a></strong>.</li>
      <li><span style="color:Red">2022.12</span>, Our TransZero++ is accepted to <strong><i>TPAMI</i></strong>.</li>
      <li><span style="color:Red">2022.10</span>, I was invited as a Reviewer for <strong><i>ICLR'23</i></strong>.</li>
      <li><span style="color:Red">2022.08</span>, I was invited as a Program Committee (PC) Member for <strong><i>AAAI'23</i></strong>.</li>
      <li><span style="color:Red">2022.05</span>, I give a talk about our CVPR'22 work (MSDN) in VALSE.</li>
      <li><span style="color:Red">2022.05</span>, I give a talk about zero-shot learning in AI TIME and AI Drive.</li>
      <li><span style="color:Red">2022.04</span>, one paper is accepted to <strong><i>IJCAI'22</i></strong>.</li>
      <li><span style="color:Red">2022.04</span>, We have released the full codes of <strong><a href="https://arxiv.org/pdf/2112.01683.pdf">TransZero</a></strong> accepted to AAAI'22.</li>
      <li><span style="color:Red">2022.03</span>, one paper is accepted to <strong><i>CVPR'22</i></strong>.</li>
      <li><span style="color:Red">2022.02</span>, I gave a talk in Extreme Mart (极市).</li>
      <li><span style="color:Red">2022.02</span>, one paper is accepted to <strong><i>IEEE Transactions on Neural Networks and Learning
	      Systems (TNNLS)</i></strong>.</li>
      <li><span style="color:Red">2022.02</span>, I gave a talk in AI TIME PhD-NeurIPS, invite by AI TIME.</li>
      <li><span style="color:Red">2022.01</span>, I start a Research Intern at <strong>Tencent AI Lab</strong>.</li>
      <li><span style="color:Red">2021.12</span>, one paper is accepted to <strong><i>AAAI'22</i></strong>.</li>
      <li><span style="color:Red">2021.09</span>, one paper is accepted to <strong><i>NeurIPS'21</i></strong>.</li>
      <li><span style="color:Red">2021.07</span>, one paper is accepted to <strong><i>ICCV'21</i></strong>.</li>
      <li ><span style="color:Red">2021.05</span>, I start a Research Intern at <strong>Alibaba DAMO Academy</strong>.</li>
      <!--<li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2021.04.29</span>, one co-authored paper is accepted to <strong><i>IJCAI'21</i></strong>.</li>
      <li><span style="color:Red">2021.02</span>, one paper is accepted to <strong><i>IEEE Transactions on Evolutionary Computation (TEVC)</i></strong>.</li>
      <li><span style="color:Red">2019.09</span>, I start my Ph.D study in EIC at <strong>HUST</strong>.</li>
      <li><span style="color:Red">2019.01</span>, one paper is accepted to <strong><i>Information Sciences (INS)</i></strong>.</li>
      <li><span style="color:Red">2018.10</span>, one paper is accepted to <strong><i>ACTA AUTOMATICA SINICA</i></strong>. </li> -->
    </div>
     
 


     <h2>Researches</h2>
    <div id="news-content" >
	   <span>
         A key challenge of artificial intelligence is to generalize machine learning models from seen data to unseen scenarios.
	<strong><i>Zero-shot learning (ZSL)</i></strong> is a typical research topic targeting this goal. ZSL aims to classify the images of unseen classes by constructing a mapping relationship between the semantic and visual domains.
	Although ZSL has achieved significant progress, there have a numbers of essential challenges.<br><br>
		   
         Dr. Shiming Chen has been focusing on tackling bottleneck challenges to promote ZSL, covering fundamental questions of
         <i>How to enhance the visual features by alleviating the cross-dataset bias between ImageNet and ZSL benchmarks? 
	 How to discover the intrinsic semantic knowledge by alleviating the visual-semantic domain shift problem? 
	How to align the visual and semantic features in a common space by reducing the discrepancy between the heterogeneous visual-semantic representations?</i>
	Specifically, his three representatives research projects are: <br> <br> 
	
         <strong>1. Developing the visual feature enhancement algorithms to tackle the challenge of cross-dataset bias in ZSL. </strong> 
         As for the embedding-based ZSL, a graph-guided dual attention network is introduced to fuse the local visual features and explicit global visual features
	to enhance visual features. As for the generative ZSL, several feature refinement learning methods are proposed to enhance the visual features and encourage
	the generator to synthesize realistic visual features for unseen classes. The papers of this project have been published in 
	<i> ICCV'21, IEEE TEC'21, IJCAI'22, IEEE TNNLS'22, IEEE TPAMI'22, </i>, etc.<br> <br> 
		   
        <strong>2. Developing the effective ZSL algorithms to tackle the visual-semantic domain shift problem. </strong> 
	As for the embedding-based ZSL, a attribute-guided Transformer network and mutually semantic distillation network are proposed to learn the intrinsic 
	semantic knowledge, enriching the visual features with semantic information to enable desirable semantic knowledge transfer from seen calsses to unseen ones.
	As for the generative ZSL, dynamic semantic prototype learning is proposed to refine the pre-defined semantic prototypes under the guidance of visual signal,
	 aligning the empirical and actual semantic prototypes for synthesizing accurate visual features. The papers of this project have been published in 
	<i>CVPR'22, AAAI'22, ICML'23</i>, etc.<br> <br> 
		   
       <strong>3. Developing the hierarchical semantic-visual adaptation framework for visual-semantic alignment.</strong> 
	Different to existing one-step adaptation method that on alignment the feature distributions between visual and semantic domains, 
	this method utilizes a hierarchical adaptation to learn an intrinsic common space for semantic and visual feature representations
	by adopting sequential structure adaptation and distribution adaptation. The papers of this project have been published in <i>NeurIPS'21</i>.
	</span> <br> <br> 
	<span></span><br>
<!-- 	  <span>I come from Meizhou, Guangdong, where is known as “<i>Hakka capital</i>” and “<i> City of Football </i>”.<br> -->
<!-- 	  <span>I currently a Postdoctoral Research Fellow in the <a href="https://www.cmu.edu/dietrich/causality/">Causal Learning and Reasoning (CLeaR)</a> research group at CMU and the <a href="https://mbzuai.ac.ae/research/research-center/ciai/">Center for Integrative AI (CIAI)</a> at MBZUAI, working with Prof.  <a href="https://www.andrew.cmu.edu/user/kunz1/index.html">Kun Zhang</a>. Prior to that, I received my Ph.D. degree at Huazhong University of Science and Technology in 2022, advised by Prof. <a href="http://bmal.hust.edu.cn/info/1005/1091.htm">Xinge You</a>.
	  I was also visiting at <a href="https://www.tmllab.ai/">Trustworthy Machine Learning Lab (TML Lab)</a>, University of Sydney, working with Prof. <a href="https://tongliang-liu.github.io/index.html">Tongliang Liu</a>.
          My current research interests span computer vision and machine learning with a series of topics, such as <strong><i>zero-shot learning</i></strong>, <strong><i>generative modeling and learning</i></strong>, and <strong><i>visual-and-language learning</i></strong>. I am the <a href="http://valser.org/article-634-1.html">AC</a> of VALSE.</span> <br> <br> 
	  <span></span><br> -->
<!-- 	  <span style="color:Red">I'm Looking forward to a position for work or postdoc researcher, please feel free to drop me an email if you have the relevant position.</span> -->
    </div>
	  
     
<tr><tr><tr><tr>
<div style="margin-top: 10px"></div>
    <h2>Selected Publications <a href="https://scholar.google.com/citations?hl=en&user=botczdcAAAAJ">(Google Scholar)</a> </h2>
<!--<p><a href="https://scholar.google.com/citations?hl=en&user=botczdcAAAAJ">My Google Scholar</a></p>-->
	 
<!--<table id="tbPublications" width="100%">
	<tbody>
<h3 style="color: red">Preprints</h3>
		
   <tr>	
		<td width="206">
		<img src="img/TransZero-TPAMI.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="TransZero-pp/TransZero-pp.html" target="_blank">TransZero++: Cross Attribute-guided Transformer for Zero-Shot Learning.</a><br>
		<p ><strong>Shiming Chen</strong>, Ziming Hong, Guo-Sen Xie, Jian Zhao, Xinge You, Shuicheng Yan, Ling Shao.</p>
        <p class="post-date" style="margin-top: -10px" ><i>arXiv preprint arXiv: 2111.04254</i>, 2021. <strong>
		[<a href="TransZero-pp/TransZero-pp.html">Project Page</a>][<a href="http://arxiv.org/abs/2112.08643">arXiv</a>]
		[<a href="https://github.com/shiming-chen/TransZero_pp">Code</a>]</strong>
		</p>		
	 <p style="margin-top: -11px"><span style="color:Green">Submitted to <i>IEEE Transactions Pattern Analysis and Machine Intelligence (<strong> TPAMI </strong>)</i> (Minor Revision)</span></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    
 </tbody>
</table>-->	      
<table id="tbPublications" width="100%">
<tbody>
<span>(*:Co-First Author; #:Corresponding Author) </span>
<h3 style="color: red">Conference Papers </h3>	
<tr>
	
		<td width="206">
		<img src="img/ICML23-DSP.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="" target="_blank"> Evolving Semantic Prototype Improves Generative Zero-Shot Learning.</a>
			<strong>[<a href="https://proceedings.mlr.press/v202/chen23l/chen23l.pdf">PDF</a>]</strong><br>
				[<a href="https://arxiv.org/pdf/2306.06931.pdf">arXiv</a>]
<!-- 				[<a href="https://github.com/shiming-chen/HSVA">Code</a>]</strong><br> -->
		 <p ><strong>Shiming Chen</strong>, Wenjin Hou, Ziming Hong, Xiaohan Ding, Yibing Song, Xinge You, Tongliang Liu, Kun Zhang.</p>
       <p style="margin-top: -11px"><i>The Fortieth International Conference on Machine Learning (<strong> ICML </strong>), 2023. <strong>(<span style="color:Burlywood">CCF Rank-A</span>)</strong> </i></p>
		</td>
	</tr>
	<tr></tr>
	<tr></tr>	

<tr>
	
		<td width="206">
		<img src="img/motivation-new.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://proceedings.neurips.cc/paper/2021/hash/8b0d268963dd0cfb808aac48a549829f-Abstract.html" target="_blank"> HSVA: Hierarchical Semantic-Visual Adaptation for Zero-Shot Learning.</a>
			<strong>[<a href="https://proceedings.neurips.cc/paper/2021/file/8b0d268963dd0cfb808aac48a549829f-Paper.pdf">PDF</a>]
				[<a href="https://arxiv.org/abs/2109.15163">arXiv</a>]
				[<a href="https://github.com/shiming-chen/HSVA">Code</a>]</strong><br>
		 <p ><strong>Shiming Chen</strong>, Guo-Sen Xie, Qinmu Peng, Yang Liu, Baigui Sun, Hao Li, Xinge You, Ling Shao.</p>
       <p style="margin-top: -11px"><i>Annual Conference on Neural Information Processing Systems (<strong> NeurIPS </strong>), 2021: 16622-16634. <strong>(<span style="color:Burlywood">CCF Rank-A</span>)</strong> </i></p>
		</td>
	</tr>
	<tr></tr>
	<tr></tr>	

<tr>
	
		<td width="206">
		<img src="img/FREE.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Chen_FREE_Feature_Refinement_for_Generalized_Zero-Shot_Learning_ICCV_2021_paper.html" target="_blank">
			FREE: Feature Refinement for Generalized Zero-shot Learning.</a>
			<strong>[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_FREE_Feature_Refinement_for_Generalized_Zero-Shot_Learning_ICCV_2021_paper.pdf">PDF</a>]
				[<a href="https://arxiv.org/abs/2107.13807">arXiv</a>]</strong>
			<strong>[<a href="https://github.com/shiming-chen/FREE">Code</a>]</strong><br>
		 <p ><strong>Shiming Chen</strong>, Wenjie Wang, Beihao Xia, Qinmu Peng, Xinge You, Feng Zheng, Ling Shao.</p>
       <p style="margin-top: -11px"><i> IEEE International Conference on Computer Vision (<strong> ICCV </strong>), 2021: 1106-1112. <strong>(<span style="color:Burlywood">CCF Rank-A</span>)</strong> </i></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>	    
	    
<tr>
	
		<td width="206">
		<img src="img/CVPR22.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Chen_MSDN_Mutually_Semantic_Distillation_Network_for_Zero-Shot_Learning_CVPR_2022_paper.html" target="_blank"> MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning.</a>
			<strong>[<a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_MSDN_Mutually_Semantic_Distillation_Network_for_Zero-Shot_Learning_CVPR_2022_paper.pdf">PDF</a>]
				[<a href="https://arxiv.org/abs/2203.03137">arXiv</a>]
				[<a href="https://github.com/shiming-chen/MSDN">Code</a>]</strong><br>
		 <p ><strong>Shiming Chen</strong>, Ziming Hong,  Guo-Sen Xie, Wenhan Yang, Qinmu Peng, Kai Wang, Jian Zhao, Xinge You.</p>
       <p style="margin-top: -11px"><i>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong> CVPR </strong>), 2022: 7612-7621. <strong>(<span style="color:Burlywood">CCF Rank-A</span>)</strong> </i></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>	
	
	

	
	
<tr>
	
		<td width="206">
		<img src="img/TransZero-AAAI22.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/19909" target="_blank"> TransZero: Attribute-guided Transformer for Zero-Shot Learning.</a>
			<strong>[<a href="https://ojs.aaai.org/index.php/AAAI/article/view/19909">PDF</a>]</strong>
			<strong>[<a href="https://arxiv.org/pdf/2112.01683.pdf">arXiv</a>]</strong>
			<strong>[<a href="https://github.com/shiming-chen/TransZero">Code</a>]</strong><br>
		 <p ><strong>Shiming Chen<sup>*</sup></strong>, Ziming Hong<sup>*</sup>, Yang Liu, Guo-Sen Xie, Baigui Sun, Hao Li, Qinmu Peng, Ke Lu, Xinge You.</p>
       <p style="margin-top: -11px"><i>Thirty-Sixth AAAI Conference on Artificial Intelligence (<strong> AAAI </strong>), 2022: 330-338. <strong>(<span style="color:Burlywood">CCF Rank-A</span>)</strong> </i></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	
   
	

  
    <tr>	
		<td width="206">
		<img src="img/IJCAI22.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="https://www.ijcai.org/proceedings/2022/134" target="_blank">Semantic Compression Embedding for Generative Zero-Shot Learning.</a><br>
		<p >Ziming Hong*</strong>, <strong>Shiming Chen<sup>*#</sup></strong>, Guo-Sen Xie, Wenhan Yang, Jian Zhao, Yuanjie Shao, Qinmu Peng, Xinge You</p>
	       <p style="margin-top: -11px"><i>The 31th International Joint Conference on Artificial Intelligence (<strong> IJCAI </strong>), 2022: 956-963. <strong>(<span style="color:Burlywood">CCF Rank-A</span>)</strong>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>


   <tr>	
		<td width="206">
		<img src="img/ICCV23-PCGNet.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="https://www.ijcai.org/proceedings/2022/134" target="_blank">Both Diverse and Realism Matter: Physical Attribute and Style Alignment for Rainy Image Generation.</a><br>
		<p > Changfeng Yu, <strong>Shiming Chen<sup></sup></strong>, Yi Chang, Yibing Song, Luxin Yan</p>
	       <p style="margin-top: -11px"><i>IEEE International Conference on Computer Vision (<strong> ICCV </strong>), 2023. <strong>(<span style="color:Burlywood">CCF Rank-A</span>)</strong>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

		       
     <tr>	
		<td width="206">
		<img src="img/IJCAI21.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="https://www.ijcai.org/proceedings/2021/0153.pdf" target="_blank">Norm-guided Adaptive Visual Embedding for Zero-Shot Sketch-Based Image Retrieval.</a>
			<strong>[<a href="https://www.ijcai.org/proceedings/2021/0153.pdf">PDF</a>]</strong><br>
		<p >Wenjie Wang, Yufeng Shi, <strong>Shiming Chen</strong>, Qinmu Peng, Feng Zheng, Xinge You</p>
	       <p style="margin-top: -11px"><i>The 30th International Joint Conference on Artificial Intelligence (<strong> IJCAI </strong>), 2021. <strong>(<span style="color:Burlywood">CCF Rank-A</span>)</strong>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>
</tbody>
</table>
		
<table id="tbPublications" width="100%">
<tbody>	
<h3 style="color: red">Journal Papers</h3>

<tr>	
		<td width="206">
		<img src="img/TransZero-TPAMI.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="https://ieeexplore.ieee.org/document/9987664" target="_blank">TransZero++: Cross Attribute-guided Transformer for Zero-Shot Learning.</a><br>
		<p ><strong>Shiming Chen</strong>, Ziming Hong, Wenjin Hou, Guo-Sen Xie,  Yibing Song, Jian Zhao, Xinge You, Shuicheng Yan, Ling Shao.</p>
        <p class="post-date" style="margin-top: -10px" > <strong>
		[<a href="TransZero-pp/TransZero-pp.html">Project Page</a>]
		[<a href="http://arxiv.org/abs/2112.08643">arXiv</a>]
		[<a href="https://ieeexplore.ieee.org/document/9987664">PDF</a>]
		[<a href="https://github.com/shiming-chen/TransZero_pp">Code</a>]</strong>
		</p>		
	 <p style="margin-top: -11px"> <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong> TPAMI </strong>), in press, 2022. <strong>
		 (<span style="color:Burlywood">SCI, IF=24.314</span>)</strong></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
	
    <tr>	
		<td width="206">
		<img src="img/GNDAN.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9768177" target="_blank">GNDAN: Graph Navigated Dual Attention Network for Zero-Shot Learning.</a>
			<strong>[<a href="https://github.com/shiming-chen/GNDAN">Code</a>]
				[<a href="">PDF</a>]</strong><br>
		<p ><strong>Shiming Chen</strong>, Ziming Hong, Guo-Sen Xie, Xinge You, Weiping Ding and Ling Shao.</p>
	       <p style="margin-top: -11px"><i>IEEE Transactions on Neural Networks and Learning Systems (<strong> TNNLS</strong>), in press, 2022. <strong>
		 (<span style="color:Burlywood">SCI, IF=14.255</span>)</strong></p>
	<tr></tr>
    <tr></tr>
    <tr></tr>
    
    <tr>	
		<td width="206">
		<img src="img/similarity-DT.png" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="https://ieeexplore.ieee.org/document/9833533" target="_blank">Kernelized Similarity Learning and Embedding for Dynamic Texture Synthesis.</a>
			<strong>[<a href="https://github.com/shiming-chen/Similariy-DT">Code</a>]
				[<a href="http://arxiv.org/abs/1911.04254">arXiv</a>]</strong>
				<!--[<a href="https://shiming-chen.github.io/Similarity-page/Similarit.html">Project Page</a>]</strong>-->        
			<br>
		<p ><strong>Shiming Chen</strong>, Peng Zhang, Guo-sen Xie, Zehong Cao, Qinmu Peng, Wei Yuan, Xinge You.</p>
	       <p style="margin-top: -11px"><i>IEEE Transactions on Systems, Man and Cybernetics: Systems (<strong> TSMCA</strong>), 53(2):824-837, 2023. <strong> 
		 (<span style="color:Burlywood">SCI, IF=11.471</span>)</strong></p>
	<tr></tr>
    <tr></tr>
    <tr></tr>
		       
		      
    <tr>	
		<td width="206">
		<img src="CDE-GAN-website/figures/CDEGAN-pipeline.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="CDE-GAN-website/CDE-GAN.html" target="_blank">CDE-GAN: Cooperative Dual Evolution Based Generative Adversarial Network.</a>
		<strong>[<a href="https://ieeexplore.ieee.org/document/9386237">PDF</a>]
		 [<a href="https://arxiv.org/abs/2008.09388">arXiv</a>]</strong>
		 <!--[<a href="CDE-GAN-website/CDE-GAN.html">Project Page</a>]</strong>-->
                 <br>
		<p ><strong>Shiming Chen</strong>, Wenjie Wang, Beihao Xia, Xinge You, Qinmu Peng, Zehong Cao, Weiping Ding.</p>
	       <p style="margin-top: -11px"><i>IEEE Transactions on Evolutionary Computation (<strong> TEVC </strong>), 25:986-1000, 2021. 
		       <strong>(<span style="color:Burlywood">SCI, IF=16.497</span>)</strong></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

   
    
	
<!--     <tr>
	
		<td width="206">
		<img src="img/INS19.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td> <a href="https://www.sciencedirect.com/science/article/pii/S0020025519300283?via%3Dihub" target="_blank"> Semi-Supervised Feature Learning for Improving Writer Identification.</a>
			<strong>[<a href="https://github.com/shiming-chen/Writer-Identification-WLSR">Code</a>]</strong><br>
		 <p ><strong>Shiming Chen</strong>, Yisong Wang, Chin-Teng Lin, Weiping Ding, Zehong Cao.</p>
        <p class="post-date" style="margin-top: -10px" ><i>Information Sciences (<strong> INS </strong>)</i>, 482:156-170, 2019. 
		<strong>(<span style="color:Burlywood">SCI, IF=8.233</span>)</strong></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr>

    <tr>
		<td width="206">
		<img src="img/ACTA18.jpg" width="185px" height = "95" style="box-shadow: 4px 4px 8px #888">
		</td>		
		<td><a href="http://www.cnki.net/kcms/doi/10.16383/j.aas.c180441.html" target="_blank"> A Robust Offline Writer Identification Method.</a>
			<strong>[<a href="https://github.com/shiming-chen/DLS-CNN">Code</a>]</strong><br>
		<p><strong>Shiming Chen</strong>, Yisong Wang.</p>
        <p class="post-date" style="margin-top: -10px" ><i>ACTA AUTOMATICA SINICA (自动化学报)</i>, 46(1):108-116, 2020.  
		<strong>(<span style="color:Burlywood">In Chinese, CAA-A,CCF-A,卓越期刊</span>)</strong></p>
		</td>
	</tr>
	<tr></tr>
    <tr></tr>
    <tr></tr> -->

</tbody>
</table>
	  
	  
    <h2><strong>Awards</strong></h2>
   <div>
	<li style="margin: -10px 0px 0px 5px" ><span style="color:Red">2022.10</span>, <strong> China National Scholarship</strong>.</li>
	<li style="margin: 10px 0px 0px 5px" ><span style="color:Red">2022.08</span>, <strong>Huawei Academic Star</strong>.</li>
    </div>  
   
    <h2>Work Experience</h2>
	<ul>
	<li>
		<div style="float:left; text-align:left">Trustworthy Machine Learning Lab (TML Lab), Uinversity of Sydney, Working with Prof. <a href="https://tongliang-liu.github.io/index.html">Tongliang Liu</a></div> <div style="float:right; text-align:right">April. 2022 – Dec. 2022</div><br>
		Visiting Student<br>
		Topic: Zero-shot Learning, Noisy Label<br>
	</li>
	<li>
		<div style="float:left; text-align:left">Tencent, AI Lab. </div> <div style="float:right; text-align:right">Jan. 2022 – Dec. 2022</div><br>
		Research Intern<br>
		Topic: Zero-shot Learning, Visual-and-Language System<br>
	</li>
        <li>
		<div style="float:left; text-align:left">Alibaba DAMO Academy, Machine Intelligence, Vision Lab. Hosted by <a href="https://www.cse.msu.edu/~rongjin/">Rong Jin</a> </div> <div style="float:right; text-align:right">May. 2021 – Oct. 2021</div><br>
		Research Intern<br>
		Topic: Zero-shot Learning, Domain Adaptation, Transformer<br>
	</li>
	<li>
		<div style="float:left; text-align:left">Fortsense, In-Screen Fingerprint Group. </div> <div style="float:right; text-align:right">Apr. 2020 – Sep. 2020</div><br>
		Research Intern<br>
		Topic: Image Retrieval, Signal Verification<br>
	</li>
	
	</ul>  
	 
	 
     <h2><strong>Professional Services</strong></h2>
   <div>
	<strong>Area Chair:</strong> 
	PRCV'23, VALSE.<br>
	   
	<strong>Journal Reviewers:</strong> 
	TPAMI, IJCV, TIP, TNNLS, TEVC, TCYB, TSMCA, TITS, TII, TMM, TASE, etc.<br>
	
	<strong>Conference PC/Reviewers:</strong> 
	ICLR'23, NeurIPS'23, IJCAI(2021, 2022),  CVPR(2022, 2023), ICCV (2021,2023), ECCV'22, ACM MM'21, AAAI(2022,2023).
    </div>
	
	 
     <h2>Invited Talks</h2>
	<ul>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>School of Information Science and Technology, University of Science and Technology of China </strong></div> <div style="float:right; text-align:right">Jun. 2023</div><br>
		<strong>Title</strong>: Zero-Shot Learning in Vision<br>
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>Alibaba DAMO Academic </strong></div> <div style="float:right; text-align:right">Apr. 2023</div><br>
		<strong>Title</strong>: Semantic-Guided Zero-Shot Learning<br>
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>Department of Mathematics and Statistics, Huazhong Agricultural Univeristy</strong></div> <div style="float:right; text-align:right">Apr. 2023</div><br>
		<strong>Title</strong>: Attribute Based Zero-Shot Learning<br>
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>School of Computer Science and Technology, Guizhou University</strong></div> <div style="float:right; text-align:right">Apr. 2023</div><br>
		<strong>Title</strong>: Semantic-Guided Zero-Shot Learning<br>
	</li>
	
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>National Key Laboratory of Science and Technology on Multispectral Information Processing, Huazhong University of Science and Technology</strong></div> <div style="float:right; text-align:right">Mar. 2023</div><br>
		<strong>Title</strong>: Deep Feature Representations Based Zero-Shot Learning<br>
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>IEEE International Conference on Digital Twins and Parallel Intelligence</strong></div> <div style="float:right; text-align:right">Nov. 2022</div><br>
		<strong>Title</strong>: Mutually Semantic Distillation Network for Zero-Shot Learning<br>
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>Huawei (Shanghai)</strong></div> <div style="float:right; text-align:right">Aug. 2022</div><br>
		<strong>Title</strong>: Deep Feature Representations Based Zero-Shot Image Classification<br>
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>Zhidongxi (AI New Youth)</strong></div> <div style="float:right; text-align:right">Aug. 2022</div><br>
		<strong>Title</strong>: MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning<br>
<!-- 		<strong>Link</strong>: 
		[<a href="https://apposcmf8kb5033.h5.xiaoeknow.com/v2/course/alive/l_62f36b2ee4b0eca59c2127c7?type=2&app_id=appoSCMf8kb5033&pro_id=p_6214b182e4b066e96087ec57&available=true&share_user_id=u_628c93c5dc641_P1UyQhrGmR&share_type=5&scene=%E5%88%86%E4%BA%AB&share_scene=1&entry=2&entry_type=2002&state=3e66fce1cd6f09304d0691d2f4f91ef9_tDzhxX">Video</a>] -->
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>VALSE</strong></div> <div style="float:right; text-align:right">Jun. 2022</div><br>
		<strong>Title</strong>: Mutually Semantic Distillation Network for Zero-Shot Learning<br>
<!-- 		<strong>Link</strong>: [<a href="https://mp.weixin.qq.com/s/EpzaYMd49QZk8qE0Q271iA">VALSE</a>]
		[<a href="https://www.bilibili.com/video/BV1ag411o7kz?spm_id_from=333.337.search-card.all.click">Video</a>] -->
	</li>
 	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>AI Drive</strong></div> <div style="float:right; text-align:right">Jun. 2022</div><br>
		<strong>Title</strong>: Mutually Semantic Distillation Network for Zero-Shot Learning<br>
<!-- 		<strong>Link</strong>: [<a href="https://www.bilibili.com/video/BV1ag411o7kz?spm_id_from=333.337.search-card.all.click">Video</a>] -->
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>AI TIME</strong></div> <div style="float:right; text-align:right">Jun. 2022</div><br>
		<strong>Title</strong>: Attribute-guided Transformer for Zero-Shot Learning<br>
<!-- 		<strong>Link</strong>: [<a href="https://www.bilibili.com/video/BV1kR4y1w7yj">Video</a>] -->
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>Extreme Mart (极市)</strong></div> <div style="float:right; text-align:right">Feb. 2022</div><br>
		<strong>Title</strong>: Research on Key Technology for Zero-shot Learning<br>
<!-- 		<strong>Link</strong>: [<a href="https://www.bilibili.com/video/BV14b4y1W7dp/">Video</a>] -->
	</li>
       <li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>AI TIME</strong></div> <div style="float:right; text-align:right">Feb. 2022</div><br>
		<strong>Title</strong>: 基于层次适应的零样本学习<br>
<!-- 	       <strong>Link</strong>: [<a href="https://www.bilibili.com/video/BV1X44y1H7S4">Video</a>] -->
	</li>
        <li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>CVTE</strong></div> <div style="float:right; text-align:right">Dec. 2021</div><br>
		<strong>Title</strong>: The Overview of Zero-Shot Learning<br>
	</li>
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>Tencent AI Lab </strong></div> <div style="float:right; text-align:right">Dec. 2021</div><br>
		<strong>Title</strong>: The Frontiers in Zero-Shot Learning<br>
	</li>
		
	<li>
		<div style="float:left; text-align:left; color:＃BDB76B"><strong>Alibaba DAMO Academic </strong></div> <div style="float:right; text-align:right">Aug. 2021</div><br>
		<strong>Title</strong>: Hierarchical Semantic-Visual Adaptation for Zero-Shot Learning<br>
	</li>
	
	</ul> 

     
	
   
	  
	  
	  
    <!--
    <div id="content-title" style="margin-top: 5px">
      <h2><strong>Links to my mentors and friends</strong></h2>
      <p style="margin-top: -10px">
	<a href="https://www.uts.edu.au/staff/chin-teng.lin">Prof. Chin-Teng Lin</a>(UTS, Australia, <strong>IEEE Fellow</strong>),&nbsp; &nbsp;
        <a href="https://www.researchgate.net/profile/Weiping_Ding2">Prof. Weiping Ding</a>(NTU, China),&nbsp; &nbsp;
	<a href="https://czh513.github.io/">Prof. Zehong Cao</a>(UTS, Australia),&nbsp; &nbsp;
	<a href="https://www.researchgate.net/profile/Yisong_Wang5">Prof. Yisong Wang</a>(GZU, China),&nbsp; &nbsp;
        <a href="http://zdzheng.xyz/index.html">Dr. Zhedong Zheng</a>(UTS, Australia),&nbsp; &nbsp;
	<a href="https://yaxingwang.github.io/">Dr. Yaxing Wang</a>(UAB, Span),&nbsp; &nbsp;
	<a href="http://www5.cs.fau.de/en/our-team/christlein-vincent">Dr. Vicent Christlein</a>(FAU, Germany),&nbsp; &nbsp;

      </p>
    </div>
    -->
	  
	  
	  

     <div id="footer">
	<div id="footer-text"></div>
    </div>
    <div id = "logo" style="margin-top: 10px; text-align:center">
	    <div align="center" style="margin:auto;padding-top:10px">
            <div style="width:12%">
                <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=kKMhkSHMeApLgHGqTfk5xOrHScwhlrHiRwRbeYjigWg"></script>
            </div>
           <br>
        &copy; Shiming Chen | <span style="color:Red">Last updated: Augst 01, 2022</span>
            </div>
     </div>     
	
   <!-- <div id = "logo" style="margin-top: 10px; text-align:center">
    <a href="http://www.hust.edu.cn/"><img  src="img/HUST.jpg" height="65px"  /></a> 
     <a href="http://www.gzu.edu.cn/"><img  src="img/GZU.jpg" height="65px" style="margin-left: 50px"/></a> -->
    

    
  </div>

</body></html>
